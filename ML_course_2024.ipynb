{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTkRqwBgay7nugqreX4SvK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheophileZuber/2024_MLEES/blob/main/ML_course_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The two models SoftMax regression and Random Forest script are in this notbook. The first two cells in the note book do not need to be ran, they just describ some of the preprocessing that was done to the real data and also how the synthetic data have been generated."
      ],
      "metadata": {
        "id": "0iekte93yq54"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data formating (DO NOT WORK WITH SYNTHETIC DATA)\n",
        "No need of running"
      ],
      "metadata": {
        "id": "nRR_EEuYDkkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os  # For file system operations\n",
        "from datetime import datetime  # For working with dates and times\n",
        "import numpy as np  # For numerical computations\n",
        "import pandas as pd  # For data manipulation and analysis\n",
        "from sklearn.metrics import (  # Metrics for evaluating model performance\n",
        "    accuracy_score,  # Calculates prediction accuracy\n",
        "    classification_report,  # Provides detailed classification metrics\n",
        "    confusion_matrix,  # Generates a confusion matrix\n",
        "    ConfusionMatrixDisplay,  # Plots the confusion matrix\n",
        "    matthews_corrcoef  # Computes Matthews correlation coefficient for classification tasks\n",
        ")\n",
        "from sklearn.model_selection import StratifiedGroupKFold, GridSearchCV, train_test_split  # For cross-validation and splitting data\n",
        "from sklearn.ensemble import RandomForestClassifier  # Random Forest algorithm for classification\n",
        "import matplotlib.pyplot as plt  # For visualizations\n",
        "import seaborn as sns  # Enhances plotting capabilities\n",
        "import joblib  # For saving/loading Python objects like trained models\n",
        "from google.colab import drive  # To interact with Google Drive in Google Colab\n",
        "\n",
        "# Mount Google Drive to access datasets and save results\n",
        "if not os.path.exists('/content/drive'):  # Check if the drive is already mounted\n",
        "    drive.mount('/content/drive')  # Mount the drive if not already mounted\n",
        "else:\n",
        "    print(\"Drive is already mounted.\")  # Skip mounting if already done\n",
        "\n",
        "# Create an output directory for saving results\n",
        "output_dir = \"/content/drive/MyDrive/Model_results/RF/\"  # Directory path for results\n",
        "os.makedirs(output_dir, exist_ok=True)  # Create the directory if it does not exist\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/data/NoImputation.csv\")  # Read the CSV file into a pandas DataFrame\n",
        "\n",
        "# Preprocess the data\n",
        "data['timestamp'] = pd.to_datetime(data['timestamp'])  # Convert 'timestamp' column to datetime objects\n",
        "data['hour'] = data['timestamp'].dt.hour  # Extract the hour of the day from the timestamp\n",
        "data['day_of_week'] = data['timestamp'].dt.dayofweek  # Extract the day of the week (0=Monday, 6=Sunday)\n",
        "\n",
        "# Add cyclical features for time-based data\n",
        "data['hour_sin'] = np.sin(2 * np.pi * data['hour'] / 24)  # Sine transformation for hours\n",
        "data['hour_cos'] = np.cos(2 * np.pi * data['hour'] / 24)  # Cosine transformation for hours\n",
        "data['day_sin'] = np.sin(2 * np.pi * data['day_of_week'] / 7)  # Sine transformation for days\n",
        "data['day_cos'] = np.cos(2 * np.pi * data['day_of_week'] / 7)  # Cosine transformation for days\n",
        "\n",
        "# Sort the data for sequential processing\n",
        "data.sort_values(by=['Ind_ID', 'timestamp'], inplace=True)  # Sort by individual ID and timestamp\n",
        "\n",
        "# Drop columns that are unnecessary for modeling\n",
        "data = data.drop(columns=[\"target_Grooming_actor\", \"Grooming_actor\"])  # Remove specific irrelevant columns\n",
        "\n",
        "# Define the group column and target columns\n",
        "group_column = 'Ind_ID'  # Grouping variable (e.g., individual IDs)\n",
        "target_columns = [col for col in data.columns if col.startswith('target_')]  # Identify target columns dynamically\n",
        "\n",
        "# Define the feature columns\n",
        "feature_columns = [\n",
        "    'speed_ms', 'stepLenght', 'turnAngle_sin', 'turnAngle_cos',  # Basic movement features\n",
        "    'hour_sin', 'hour_cos', 'day_sin', 'day_cos'  # Time-related features\n",
        "] + list(data.columns[8:34])  # Dynamically include columns from index 8 to 34 which correspond to the landcover labels and behavior labels\n",
        "\n",
        "# Ensure that target columns are detected\n",
        "target_columns = [col for col in data.columns if col.startswith('target_')]  # Reconfirm target columns\n",
        "print(f\"Target columns found: {target_columns}\")  # Display detected target columns\n",
        "\n",
        "# Create a unified target class column\n",
        "# This combines multiple one-hot-encoded target columns into a single column with class labels\n",
        "data['target_class'] = data[target_columns].idxmax(axis=1)  # Pick the column with the maximum value as the target class (the values can only be 0 or 1)\n",
        "\n",
        "# Verify that the target class column has been created\n",
        "print(f\"Target class column added: {data['target_class'].head()}\")  # Display the first few rows of the new target class column\n",
        "\n",
        "# Perform train-test split\n",
        "train_data, test_data = train_test_split(  # Split data into training and testing sets\n",
        "    data, test_size=0.2, random_state=42, stratify=data['target_class']  # Stratify to preserve class distribution\n",
        ")\n",
        "\n",
        "# Separate features (X) and target (y) for both training and testing sets\n",
        "X_train = train_data[feature_columns]  # Features for training\n",
        "y_train = train_data['target_class']  # Target variable for training\n",
        "X_test = test_data[feature_columns]  # Features for testing\n",
        "y_test = test_data['target_class']  # Target variable for testing\n",
        "\n",
        "# Validate the shape of features and targets\n",
        "assert X_train.shape[0] == y_train.shape[0], \"Mismatch between X_train and y_train\"  # Ensure row count matches\n",
        "assert X_test.shape[0] == y_test.shape[0], \"Mismatch between X_test and y_test\"  # Ensure row count matches\n",
        "\n",
        "# Display the shapes of the train and test datasets for verification\n",
        "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")  # Print training set shape\n",
        "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")  # Print testing set shape\n",
        "\n",
        "# Extract unique classes and preserve their order\n",
        "unique_classes = data['target_class'].unique()  # Get the unique classes in the dataset\n",
        "\n",
        "# Map class names (labels) to numerical indices\n",
        "class_mapping = {class_name: idx for idx, class_name in enumerate(sorted(unique_classes))}  # Create a mapping\n",
        "print(\"Class Mapping:\", class_mapping)  # Display the mapping from class names to indices\n"
      ],
      "metadata": {
        "id": "-4vaUW2dE1mN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How the synthetic data have been generated"
      ],
      "metadata": {
        "id": "2TkjCXhPFUM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np  # For numerical operations and random sampling\n",
        "import pandas as pd  # For data manipulation and storage\n",
        "\n",
        "# Function to generate synthetic data\n",
        "def generate_synthetic_data(original_data, feature_columns, target_columns, n_samples):\n",
        "    \"\"\"\n",
        "    Generates synthetic data based on the distributions in the original dataset.\n",
        "\n",
        "    Parameters:\n",
        "        original_data (pd.DataFrame): The original dataset used as a reference.\n",
        "        feature_columns (list): List of feature column names to include in synthetic data.\n",
        "        target_columns (list): List of target column names (one-hot encoded) to generate target data.\n",
        "        n_samples (int): Number of synthetic samples to generate.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A synthetic dataset with features and target columns.\n",
        "    \"\"\"\n",
        "    # Initialize an empty DataFrame for synthetic data\n",
        "    synthetic_data = pd.DataFrame()\n",
        "\n",
        "    # Generate synthetic features by sampling from the original dataset\n",
        "    for column in feature_columns:\n",
        "        if column in original_data.columns:\n",
        "            # Sample with replacement from the original column\n",
        "            synthetic_data[column] = np.random.choice(\n",
        "                original_data[column], size=n_samples, replace=True\n",
        "            )\n",
        "\n",
        "    # Define subsets of feature columns for one-hot encoding groups\n",
        "    group_1_cols = feature_columns[8:14]  # Group 1: Columns 8-13 (0-indexed)\n",
        "    group_2_cols = feature_columns[14:31]  # Group 2: Columns 14-30 (0-indexed)\n",
        "\n",
        "    # Helper function to generate one-hot encoded data for a group of columns\n",
        "    def generate_one_hot_group(columns):\n",
        "        \"\"\"\n",
        "        Generates one-hot encoded data ensuring mutual exclusivity within a group.\n",
        "\n",
        "        Parameters:\n",
        "            columns (list): List of column names in the group.\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: One-hot encoded synthetic data for the group.\n",
        "        \"\"\"\n",
        "        group_data = np.zeros((n_samples, len(columns)))  # Initialize a zero matrix\n",
        "        for i in range(n_samples):\n",
        "            one_hot_index = np.random.choice(len(columns))  # Randomly select an index to activate\n",
        "            group_data[i, one_hot_index] = 1  # Set the selected index to 1\n",
        "        return pd.DataFrame(group_data, columns=columns)  # Convert to DataFrame with column names\n",
        "\n",
        "    # Generate synthetic one-hot encoded data for both groups\n",
        "    synthetic_group_1 = generate_one_hot_group(group_1_cols)  # Group 1 one-hot data\n",
        "    synthetic_group_2 = generate_one_hot_group(group_2_cols)  # Group 2 one-hot data\n",
        "\n",
        "    # Add generated one-hot groups to the synthetic dataset\n",
        "    synthetic_data = pd.concat([synthetic_data, synthetic_group_1, synthetic_group_2], axis=1)\n",
        "\n",
        "    # Generate synthetic target data\n",
        "    target_probs = original_data[target_columns].mean()  # Calculate the mean probabilities for each target\n",
        "    target_samples = np.random.multinomial(1, target_probs, size=n_samples)  # Sample targets using multinomial distribution\n",
        "    target_one_hot = pd.DataFrame(target_samples, columns=target_columns)  # Convert samples to a DataFrame\n",
        "\n",
        "    # Append the one-hot encoded target data to the synthetic dataset\n",
        "    synthetic_data = pd.concat([synthetic_data, target_one_hot], axis=1)\n",
        "\n",
        "    # Convert one-hot encoded targets to a single-column format\n",
        "    synthetic_data['target_class'] = target_one_hot.idxmax(axis=1)  # Use the column with the highest value as the target class\n",
        "\n",
        "    return synthetic_data  # Return the final synthetic dataset\n",
        "\n",
        "# Number of synthetic samples to generate\n",
        "n_samples = 20000\n",
        "\n",
        "# Generate synthetic data using the defined function\n",
        "synthetic_data = generate_synthetic_data(data, feature_columns, target_columns, n_samples)\n",
        "\n",
        "# Separate synthetic data into features (X) and target (y)\n",
        "X_synthetic = synthetic_data[feature_columns]  # Feature columns\n",
        "y_synthetic = synthetic_data['target_class']  # Target column\n",
        "\n",
        "# Display a preview of the synthetic features and target\n",
        "print(\"Synthetic Features:\")\n",
        "print(X_synthetic.head())  # Display the first few rows of synthetic features\n",
        "print(\"\\nSynthetic Target:\")\n",
        "print(y_synthetic.head())  # Display the first few rows of synthetic target\n",
        "\n",
        "# Save the synthetic data to CSV files\n",
        "X_synthetic.to_csv(\"/content/drive/MyDrive/data/synthetic_features.csv\", index=False)  # Save features to a CSV file\n",
        "y_synthetic.to_csv(\"/content/drive/MyDrive/data/synthetic_target.csv\", index=False)    # Save target to a separate CSV file\n",
        "\n",
        "# Alternatively, save the entire synthetic dataset in a single file\n",
        "synthetic_data.to_csv(\"/content/drive/MyDrive/data/synthetic_data.csv\", index=False)   # Save combined features and target\n",
        "\n",
        "# Confirm that the synthetic data has been saved\n",
        "print(\"Synthetic data saved as CSV files.\")\n"
      ],
      "metadata": {
        "id": "iNJE8D69FUmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SoftMax regression model"
      ],
      "metadata": {
        "id": "HnSTbZctDkW7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing"
      ],
      "metadata": {
        "id": "TiHUnU1ig7e0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os  # For file and directory operations\n",
        "import numpy as np  # For numerical operations and metrics calculations\n",
        "import pandas as pd  # For data manipulation and storage\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, classification_report, ConfusionMatrixDisplay, matthews_corrcoef\n",
        ")  # For model evaluation\n",
        "from sklearn.model_selection import train_test_split, StratifiedGroupKFold, GridSearchCV  # For data splitting and cross-validation\n",
        "from sklearn.linear_model import LogisticRegression  # For the softmax regression model\n",
        "import joblib  # For saving and loading models\n",
        "import matplotlib.pyplot as plt  # For plotting and saving figures\n",
        "\n",
        "# Create a directory to save results\n",
        "results_dir = \"/content/drive/MyDrive/Model_results/Softmax/\"\n",
        "os.makedirs(results_dir, exist_ok=True)  # Ensures the directory exists\n",
        "\n",
        "# Load synthetic data generated from the previous script\n",
        "synthetic_data_path = \"/content/drive/MyDrive/data/synthetic_data.csv\"\n",
        "if os.path.exists(synthetic_data_path):\n",
        "    data = pd.read_csv(synthetic_data_path)\n",
        "    print(\"Synthetic data loaded successfully.\")\n",
        "else:\n",
        "    raise FileNotFoundError(\"Synthetic data file not found. Ensure the second script has run successfully.\")\n",
        "\n",
        "# Define features and target columns\n",
        "feature_columns = [\n",
        "    'speed_ms', 'stepLenght', 'turnAngle_sin', 'turnAngle_cos',\n",
        "    'hour_sin', 'hour_cos', 'day_sin', 'day_cos'\n",
        "] + [col for col in data.columns if col.startswith('feature_')]  # Includes any additional feature columns\n",
        "\n",
        "target_columns = [col for col in data.columns if col.startswith('target_')]  # Identify one-hot encoded target columns\n",
        "\n",
        "# Convert target columns to numeric type to ensure compatibility for further processing\n",
        "for column in target_columns:\n",
        "    data[column] = pd.to_numeric(data[column], errors='coerce')  # Replace invalid values with NaN if any\n",
        "\n",
        "# Combine one-hot target columns into a single target class column\n",
        "data['target_class'] = data[target_columns].idxmax(axis=1)  # Selects the column with the maximum value in each row\n",
        "\n",
        "# Prepare data for modeling\n",
        "X = data[feature_columns]  # Features\n",
        "y = data['target_class']  # Target\n",
        "\n",
        "# Train-test split with stratification to preserve class distribution\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42, stratify=data['target_class'])\n",
        "X_train = train_data[feature_columns]\n",
        "y_train = train_data['target_class']\n",
        "X_test = test_data[feature_columns]\n",
        "y_test = test_data['target_class']\n",
        "\n",
        "# Define cross-validation strategy\n",
        "n_splits = 16  # Number of splits for StratifiedGroupKFold\n",
        "skf = StratifiedGroupKFold(n_splits=n_splits)  # Ensures balanced class distribution in each fold\n",
        "\n",
        "# Define parameter grid for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
        "    'solver': ['lbfgs', 'saga', 'newton-cg', 'liblinear'],  # Optimization solvers\n",
        "    'penalty': ['l2', 'elasticnet'],  # Regularization methods\n",
        "    'tol': [1e-4, 1e-3, 1e-2],  # Convergence tolerance\n",
        "    'fit_intercept': [True, False],  # Whether to fit the intercept\n",
        "    'class_weight': [None, 'balanced']  # Handling of class imbalance\n",
        "}\n"
      ],
      "metadata": {
        "id": "AwNtNVMJg6vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model initialisation and GridSearch"
      ],
      "metadata": {
        "id": "VuEL4N-Xg_jj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize Softmax Regression model\n",
        "softmax_model = LogisticRegression(\n",
        "    multi_class='multinomial',  # Enables softmax regression for multiclass classification\n",
        "    max_iter=1000,  # Maximum number of iterations for solver convergence\n",
        "    class_weight=\"balanced\",  # Handles class imbalance by weighting classes inversely proportional to their frequencies\n",
        "    random_state=42  # Ensures reproducibility\n",
        ")\n",
        "\n",
        "# Initialize GridSearchCV for hyperparameter tuning\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=softmax_model,\n",
        "    param_grid=param_grid,\n",
        "    cv=skf.split(X_train, y_train, groups=train_data.index),  # Cross-validation strategy\n",
        "    scoring='accuracy',  # Optimization metric\n",
        "    n_jobs=-1  # Use all available CPU cores for faster processing\n",
        ")\n",
        "\n",
        "# Perform grid search to find the best hyperparameters\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Output best parameters and the corresponding accuracy\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n",
        "\n",
        "# Use the best model identified by grid search\n",
        "best_softmax_model = grid_search.best_estimator_\n",
        "\n",
        "\n",
        "\n",
        "# Compute and save the global confusion matrix\n",
        "global_conf_matrix = confusion_matrix(all_y_true, all_y_pred)\n",
        "plt.figure(figsize=(10, 8))\n",
        "cm_display_global = ConfusionMatrixDisplay(confusion_matrix=global_conf_matrix)\n",
        "cm_display_global.plot(cmap='viridis', colorbar=True)\n",
        "plt.title(\"Global Confusion Matrix (Softmax Regression - CV)\")\n",
        "plt.savefig(os.path.join(results_dir, 'global_confusion_matrix_softmax.png'))\n",
        "plt.close()\n",
        "\n",
        "# Output global confusion matrix\n",
        "print(\"Global Confusion Matrix (CV):\")\n",
        "print(global_conf_matrix)\n",
        "\n",
        "# Save global confusion matrix to text\n",
        "np.savetxt(os.path.join(results_dir, 'global_confusion_matrix_softmax.txt'), global_conf_matrix, fmt='%d')\n",
        "\n",
        "# Compute mean validation accuracy and MCC\n",
        "mean_val_accuracy = np.mean(fold_accuracies)\n",
        "mean_mcc = np.mean(mcc_scores)\n",
        "print(f\"Mean Validation Accuracy (CV): {mean_val_accuracy:.2f}\")\n",
        "print(f\"Mean MCC (CV): {mean_mcc:.2f}\")\n",
        "\n",
        "# Save validation metrics\n",
        "cv_metrics_path = os.path.join(results_dir, 'cv_metrics.txt')\n",
        "with open(cv_metrics_path, 'w') as f:\n",
        "    f.write(f\"Mean Validation Accuracy (CV): {mean_val_accuracy:.2f}\\n\")\n",
        "    f.write(f\"Mean MCC (CV): {mean_mcc:.2f}\\n\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_test_pred = best_softmax_model.predict(X_test)\n",
        "\n",
        "# Test set metrics\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_mcc = matthews_corrcoef(y_test, y_test_pred)\n",
        "test_precision = precision_score(y_test, y_test_pred, average='weighted')\n",
        "test_recall = recall_score(y_test, y_test_pred, average='weighted')\n",
        "test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
        "print(f\"Test MCC: {test_mcc:.2f}\")\n",
        "print(f\"Test Precision: {test_precision:.2f}\")\n",
        "print(f\"Test Recall: {test_recall:.2f}\")\n",
        "print(f\"Test F1-Score: {test_f1:.2f}\")\n",
        "\n",
        "# Save test confusion matrix\n",
        "cm_test = confusion_matrix(y_test, y_test_pred)\n",
        "cm_display_test = ConfusionMatrixDisplay(confusion_matrix=cm_test)\n",
        "cm_display_test.plot(cmap='viridis')\n",
        "plt.title(\"Test Set Confusion Matrix (Softmax Regression)\")\n",
        "plt.savefig(os.path.join(results_dir, 'softmax_confusion_matrix_test.png'))\n",
        "plt.close()\n",
        "\n",
        "# Save classification report as CSV\n",
        "classification_report_dict = classification_report(y_test, y_test_pred, output_dict=True)\n",
        "classification_report_df = pd.DataFrame(classification_report_dict).transpose()\n",
        "classification_report_df.to_csv(os.path.join(results_dir, 'classification_report.csv'), index=True)\n",
        "\n",
        "# Save the final model\n",
        "joblib.dump(best_softmax_model, os.path.join(results_dir, 'softmax_final_model.pkl'))\n",
        "\n",
        "# Save global test metrics to a file\n",
        "global_metrics_path = os.path.join(results_dir, 'global_metrics.txt')\n",
        "with open(global_metrics_path, 'w') as f:\n",
        "    f.write(f\"Test Accuracy: {test_accuracy:.2f}\\n\")\n",
        "    f.write(f\"Test MCC: {test_mcc:.2f}\\n\")\n",
        "    f.write(f\"Test Precision: {test_precision:.2f}\\n\")\n",
        "    f.write(f\"Test Recall: {test_recall:.2f}\\n\")\n",
        "    f.write(f\"Test F1-Score: {test_f1:.2f}\\n\")\n"
      ],
      "metadata": {
        "id": "xIgBPnIDFmad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit and Crossvalidation with the best parameters for the model"
      ],
      "metadata": {
        "id": "PYERzDu_hS6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using cross-validation\n",
        "fold_accuracies = []  # Store accuracy for each fold\n",
        "mcc_scores = []  # Store MCC for each fold\n",
        "\n",
        "# Collect all true and predicted labels for a global confusion matrix\n",
        "all_y_true = []\n",
        "all_y_pred = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train, groups=train_data.index)):\n",
        "    print(f\"Fold {fold + 1}\")\n",
        "    X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "    y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "    # Train the model on the training portion of the fold\n",
        "    best_softmax_model.fit(X_fold_train, y_fold_train)\n",
        "\n",
        "    # Predict on the validation portion of the fold\n",
        "    y_val_pred = best_softmax_model.predict(X_fold_val)\n",
        "\n",
        "    # Collect true and predicted labels\n",
        "    all_y_true.extend(y_fold_val)\n",
        "    all_y_pred.extend(y_val_pred)\n",
        "\n",
        "    # Evaluate metrics for the fold\n",
        "    val_accuracy = accuracy_score(y_fold_val, y_val_pred)\n",
        "    val_mcc = matthews_corrcoef(y_fold_val, y_val_pred)\n",
        "    fold_accuracies.append(val_accuracy)\n",
        "    mcc_scores.append(val_mcc)"
      ],
      "metadata": {
        "id": "gP0ELPx2hRkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculation and saving of the different performance measures"
      ],
      "metadata": {
        "id": "9C4WozSFhRRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Compute and save the global confusion matrix\n",
        "global_conf_matrix = confusion_matrix(all_y_true, all_y_pred)\n",
        "plt.figure(figsize=(10, 8))\n",
        "cm_display_global = ConfusionMatrixDisplay(confusion_matrix=global_conf_matrix)\n",
        "cm_display_global.plot(cmap='viridis', colorbar=True)\n",
        "plt.title(\"Global Confusion Matrix (Softmax Regression - CV)\")\n",
        "plt.savefig(os.path.join(results_dir, 'global_confusion_matrix_softmax.png'))\n",
        "plt.close()\n",
        "\n",
        "# Output global confusion matrix\n",
        "print(\"Global Confusion Matrix (CV):\")\n",
        "print(global_conf_matrix)\n",
        "\n",
        "# Save global confusion matrix to text\n",
        "np.savetxt(os.path.join(results_dir, 'global_confusion_matrix_softmax.txt'), global_conf_matrix, fmt='%d')\n",
        "\n",
        "# Compute mean validation accuracy and MCC\n",
        "mean_val_accuracy = np.mean(fold_accuracies)\n",
        "mean_mcc = np.mean(mcc_scores)\n",
        "print(f\"Mean Validation Accuracy (CV): {mean_val_accuracy:.2f}\")\n",
        "print(f\"Mean MCC (CV): {mean_mcc:.2f}\")\n",
        "\n",
        "# Save validation metrics\n",
        "cv_metrics_path = os.path.join(results_dir, 'cv_metrics.txt')\n",
        "with open(cv_metrics_path, 'w') as f:\n",
        "    f.write(f\"Mean Validation Accuracy (CV): {mean_val_accuracy:.2f}\\n\")\n",
        "    f.write(f\"Mean MCC (CV): {mean_mcc:.2f}\\n\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_test_pred = best_softmax_model.predict(X_test)\n",
        "\n",
        "# Test set metrics\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_mcc = matthews_corrcoef(y_test, y_test_pred)\n",
        "test_precision = precision_score(y_test, y_test_pred, average='weighted')\n",
        "test_recall = recall_score(y_test, y_test_pred, average='weighted')\n",
        "test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
        "print(f\"Test MCC: {test_mcc:.2f}\")\n",
        "print(f\"Test Precision: {test_precision:.2f}\")\n",
        "print(f\"Test Recall: {test_recall:.2f}\")\n",
        "print(f\"Test F1-Score: {test_f1:.2f}\")\n",
        "\n",
        "# Save test confusion matrix\n",
        "cm_test = confusion_matrix(y_test, y_test_pred)\n",
        "cm_display_test = ConfusionMatrixDisplay(confusion_matrix=cm_test)\n",
        "cm_display_test.plot(cmap='viridis')\n",
        "plt.title(\"Test Set Confusion Matrix (Softmax Regression)\")\n",
        "plt.savefig(os.path.join(results_dir, 'softmax_confusion_matrix_test.png'))\n",
        "plt.close()\n",
        "\n",
        "# Save classification report as CSV\n",
        "classification_report_dict = classification_report(y_test, y_test_pred, output_dict=True)\n",
        "classification_report_df = pd.DataFrame(classification_report_dict).transpose()\n",
        "classification_report_df.to_csv(os.path.join(results_dir, 'classification_report.csv'), index=True)\n",
        "\n",
        "# Save the final model\n",
        "joblib.dump(best_softmax_model, os.path.join(results_dir, 'softmax_final_model.pkl'))\n",
        "\n",
        "# Save global test metrics to a file\n",
        "global_metrics_path = os.path.join(results_dir, 'global_metrics.txt')\n",
        "with open(global_metrics_path, 'w') as f:\n",
        "    f.write(f\"Test Accuracy: {test_accuracy:.2f}\\n\")\n",
        "    f.write(f\"Test MCC: {test_mcc:.2f}\\n\")\n",
        "    f.write(f\"Test Precision: {test_precision:.2f}\\n\")\n",
        "    f.write(f\"Test Recall: {test_recall:.2f}\\n\")\n",
        "    f.write(f\"Test F1-Score: {test_f1:.2f}\\n\")"
      ],
      "metadata": {
        "id": "lspMY4vohSWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SHAP values and figure"
      ],
      "metadata": {
        "id": "a930tW7hGtAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = shap.Explainer(best_rf_model, X_train)\n",
        "shap_values = explainer(X_test)\n",
        "\n",
        "# Average SHAP values across classes for a global interpretation\n",
        "shap_values_mean = shap_values.values.mean(axis=2)\n",
        "\n",
        "# Summary plot with averaged SHAP values and feature names\n",
        "shap.summary_plot(shap_values_mean, X_test, feature_names=X_test.columns)"
      ],
      "metadata": {
        "id": "kh28-5iPGpEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest model"
      ],
      "metadata": {
        "id": "V9wLrugiDd0S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing"
      ],
      "metadata": {
        "id": "dd4ySLjQtUx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    ConfusionMatrixDisplay,\n",
        "    matthews_corrcoef\n",
        ")\n",
        "from sklearn.model_selection import StratifiedGroupKFold, GridSearchCV, train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive to access data and save results\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "else:\n",
        "    print(\"Drive is already mounted.\")\n",
        "\n",
        "# Create an output directory for saving model results\n",
        "output_dir = \"/content/drive/MyDrive/Model_results/Synthetic_RF/\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Load the synthetic dataset generated in the second script\n",
        "synthetic_data = pd.read_csv(\"/content/drive/MyDrive/data/synthetic_data.csv\")\n",
        "\n",
        "# Define feature columns used for training and testing the model\n",
        "feature_columns = [\n",
        "    'speed_ms', 'stepLenght', 'turnAngle_sin', 'turnAngle_cos',\n",
        "    'hour_sin', 'hour_cos', 'day_sin', 'day_cos'\n",
        "] + list(synthetic_data.columns[8:31])  # Include synthetic one-hot-encoded features\n",
        "\n",
        "# Define target column that represents the class labels\n",
        "target_column = 'target_class'\n",
        "\n",
        "# Map class labels to numerical values for compatibility with sklearn models\n",
        "unique_classes = synthetic_data[target_column].unique()  # Extract unique classes\n",
        "class_mapping = {class_name: idx for idx, class_name in enumerate(sorted(unique_classes))}  # Create mapping\n",
        "synthetic_data[target_column] = synthetic_data[target_column].map(class_mapping)  # Apply mapping\n",
        "\n",
        "# Split the synthetic data into features and target\n",
        "X_synthetic = synthetic_data[feature_columns]  # Features\n",
        "y_synthetic = synthetic_data[target_column]  # Target\n",
        "\n",
        "# Split the data into training and test sets for final evaluation\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_synthetic, y_synthetic, test_size=0.2, random_state=42, stratify=y_synthetic\n",
        ")\n",
        "\n",
        "# Print dataset shapes to verify splits\n",
        "print(f\"Training set shape: X_train={X_train.shape}, y_train={y_train.shape}\")\n",
        "print(f\"Test set shape: X_test={X_test.shape}, y_test={y_test.shape}\")\n",
        "\n",
        "# Set up StratifiedGroupKFold for cross-validation to ensure balanced class distributions in folds\n",
        "n_splits = 16  # Number of folds\n",
        "cv = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# Define a parameter grid for hyperparameter tuning using GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100],  # Number of trees in the forest\n",
        "    'max_depth': [10, 20],  # Maximum depth of trees\n",
        "    'min_samples_leaf': [2, 4]  # Minimum samples required in leaf nodes\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "collapsed": true,
        "id": "YKim_6kLtcAC",
        "outputId": "034adbe1-d11e-458f-c1e1-3254c5b314be"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-957deb8e9eb8>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Mount Google Drive to access data and save results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Drive is already mounted.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialise the model and perform the GridSearchCV"
      ],
      "metadata": {
        "id": "288xwcLBteWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Random Forest model with balanced class weights\n",
        "rf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
        "\n",
        "# Perform grid search cross-validation for hyperparameter tuning\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=rf,\n",
        "    param_grid=param_grid,\n",
        "    cv=cv.split(X_train, y_train, groups=None),  # Use StratifiedGroupKFold\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1  # Use all available cores for computation\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)  # Train the model using grid search\n",
        "\n",
        "# Save the best model obtained from GridSearchCV\n",
        "best_model = grid_search.best_estimator_\n",
        "joblib.dump(best_model, os.path.join(output_dir, \"best_rf_model.pkl\"))\n"
      ],
      "metadata": {
        "id": "dv4VMPMHtyO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the model with the best hyperparameters using a crossvalidation"
      ],
      "metadata": {
        "id": "QaShWg1Jtysq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFQgVHlPDKEk"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model using cross-validation\n",
        "fold_accuracies = []  # Store accuracy for each fold\n",
        "fold_mcc_scores = []  # Store MCC for each fold\n",
        "all_y_true = []  # Collect true labels from all folds\n",
        "all_y_pred = []  # Collect predictions from all folds\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(cv.split(X_train, y_train, groups=None)):\n",
        "    print(f\"Processing fold {fold + 1}...\")\n",
        "\n",
        "    # Split data into training and validation sets for this fold\n",
        "    X_train_fold, X_val_fold = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "    y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "    # Train the model on the current fold\n",
        "    best_model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Make predictions for validation set\n",
        "    y_val_pred = best_model.predict(X_val_fold)\n",
        "\n",
        "    # Append true and predicted labels for overall metrics\n",
        "    all_y_true.extend(y_val_fold)\n",
        "    all_y_pred.extend(y_val_pred)\n",
        "\n",
        "    # Calculate metrics for this fold\n",
        "    accuracy = accuracy_score(y_val_fold, y_val_pred)\n",
        "    mcc = matthews_corrcoef(y_val_fold, y_val_pred)\n",
        "    fold_accuracies.append(accuracy)\n",
        "    fold_mcc_scores.append(mcc)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save performance metrics"
      ],
      "metadata": {
        "id": "sbqCiwxDyR7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate overall metrics across all folds\n",
        "overall_accuracy = np.mean(fold_accuracies)  # Mean accuracy\n",
        "overall_mcc = np.mean(fold_mcc_scores)  # Mean MCC\n",
        "\n",
        "# Print cross-validation results\n",
        "print(f\"Mean CV Accuracy: {overall_accuracy:.2f}\")\n",
        "print(f\"Mean CV MCC: {overall_mcc:.2f}\")\n",
        "\n",
        "# Evaluate the model on the independent test set\n",
        "print(\"Evaluating on the test set...\")\n",
        "y_test_pred = best_model.predict(X_test)  # Make predictions on test data\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)  # Test accuracy\n",
        "test_mcc = matthews_corrcoef(y_test, y_test_pred)  # Test MCC\n",
        "\n",
        "# Print test results\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
        "print(f\"Test MCC: {test_mcc:.2f}\")\n",
        "\n",
        "# Save confusion matrix for the test set\n",
        "cm = confusion_matrix(y_test, y_test_pred, labels=range(len(unique_classes)))\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=unique_classes, yticklabels=unique_classes)\n",
        "plt.title(\"Confusion Matrix (Test Set)\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "conf_matrix_path = os.path.join(output_dir, \"test_confusion_matrix.png\")\n",
        "plt.savefig(conf_matrix_path)\n",
        "plt.show()\n",
        "\n",
        "# Save feature importances plot\n",
        "importances = best_model.feature_importances_  # Feature importances from the model\n",
        "sorted_indices = np.argsort(importances)[::-1]  # Sort indices by importance (descending)\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(\n",
        "    x=importances[sorted_indices][:15],\n",
        "    y=np.array(feature_columns)[sorted_indices][:15],\n",
        "    palette=\"viridis\"\n",
        ")\n",
        "plt.title(\"Top 15 Feature Importances\")\n",
        "plt.xlabel(\"Importance\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.tight_layout()\n",
        "feature_importance_path = os.path.join(output_dir, \"feature_importances.png\")\n",
        "plt.savefig(feature_importance_path)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "c7WMekccyRy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SHAP values and figure\n"
      ],
      "metadata": {
        "id": "jhemxB9fFLpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = shap.Explainer(best_rf_model, X_train)\n",
        "shap_values = explainer(X_test)\n",
        "\n",
        "# Average SHAP values across classes for a global interpretation\n",
        "shap_values_mean = shap_values.values.mean(axis=2)\n",
        "\n",
        "# Summary plot with averaged SHAP values and feature names\n",
        "shap.summary_plot(shap_values_mean, X_test, feature_names=X_test.columns)"
      ],
      "metadata": {
        "id": "ajVZqXyXGHDX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}